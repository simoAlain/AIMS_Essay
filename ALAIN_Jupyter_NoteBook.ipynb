{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "292c48e0",
   "metadata": {},
   "source": [
    "<h1>Warning: You may need <b><u>MY</u></b> modified dataset to run this code</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43b7dbe",
   "metadata": {},
   "source": [
    "# Notebook By Alain: Deep learning techniques for MRI brain tumors classification\n",
    "<p>The Aim of this notebook is to show the progression of my work. What I am doing here is I am trying to explain my pre-processing and modelling.</p>\n",
    "<p>I began by downloading the prescribed dataset. The dataset contains four classes: no tumor. puitary, glioma, menigngioma. These images have different sizes, so the first part of the preprocessing is to harmonize the dataset by given to all the images the same size. In the data set, the following propotion is respected for training and testing respectively: </p>\n",
    "<ul>\n",
    "    <li>no tumor: 395/105</li>\n",
    "    <li>pituitary: 827/74</li>\n",
    "    <li>menigngioama: 822/115</li>\n",
    "    <li>glioma: 826/100</li>\n",
    "</ul> \n",
    "<p>What does the above proportion tell us? It tells us that there are 2475 images for tumorous brain and 395 for non-tumorous brain.</p>\n",
    "<p> Recall that the modelling part of the work is in two steps, the first consist of building a model which will be able to differentiate between tumorous and non tumorous brain, the secong step consist in a model which is able to differentiate between the type of tumors. If we want to proceed with the first model, we need a dataset in which the images for each label are almost of equal size so that the model shuld not be bias. In this particullar case, i used rotation and fflipping in order to augment the number of images for non-tumorous. I ended with the proportion 2370/2475 for non-tumorous/tumorous, which is more fair. Fpor the second part of the modelling, the images are almost equal in number for different label; hence we don;t need any data augmentation. </p>\n",
    "<p> Let's now follow the notebook for explanation on preprocessing and modelling</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a68fa4",
   "metadata": {},
   "source": [
    "# Setting the database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976f4629",
   "metadata": {},
   "source": [
    "<p>Here, we are trying to build a database of the images and their labels. Our aim is to build a two stage neural network. The first stage will tell you if the brain is sick or not and the second stage will identify the disease.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22d6cb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 08:04:54.822888: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-11 08:04:55.001767: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-05-11 08:04:55.001789: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-05-11 08:04:55.779466: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-11 08:04:55.779556: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-11 08:04:55.779565: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "#We import some library in this cell and then we are going to use the differents folder to buils the dataset\n",
    "# A training and testing dataset\n",
    "from PIL import Image\n",
    "from numpy import array\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from warnings import filterwarnings\n",
    "import warnings\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras import optimizers\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,BatchNormalization,Dropout,GlobalAveragePooling2D,GlobalMaxPooling2D,Activation,Lambda,ZeroPadding2D\n",
    "tf.keras.backend.clear_session()\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "import io\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac13687f",
   "metadata": {},
   "source": [
    "### Data Preparation for te first model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d19eb4",
   "metadata": {},
   "source": [
    "<p>In what follows, I transform the images into matrices and I am storing them into a pandas dataframe. I proceed in two steps. The first step consist of building tow datasets for the first model ie one for training and the other for testing the sameting is done for the second model. The pandas dataframe contains two column; one for images, one for labels. For the fist model, we have two label(1: tumorous, 1:non-tumorous). This is what I am doing in the following cells.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fe8f4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=['no_tumor','tumor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b0b7bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1980/1980 [00:02<00:00, 704.08it/s]\n",
      "100%|██████████| 2075/2075 [00:05<00:00, 347.12it/s]\n",
      "100%|██████████| 420/420 [00:00<00:00, 3913.07it/s]\n",
      "100%|██████████| 289/289 [00:00<00:00, 381.21it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "image_size = 128\n",
    "for i in labels:\n",
    "    folderPath = os.path.join('/home/dsam/AIMS_CMR/Essay_Alain/dataset/Get_to_work/Brain_2_work','Training',i)\n",
    "    for j in tqdm(os.listdir(folderPath)):\n",
    "        img = cv2.imread(os.path.join(folderPath,j))\n",
    "        img = cv2.resize(img,(image_size,image_size))\n",
    "        X_train.append(img)\n",
    "        y_train.append(i)\n",
    "for i in labels:\n",
    "    folderPath = os.path.join('/home/dsam/AIMS_CMR/Essay_Alain/dataset/Get_to_work/Brain_2_work','Testing',i)\n",
    "    for j in tqdm(os.listdir(folderPath)):\n",
    "        img = cv2.imread(os.path.join(folderPath,j))\n",
    "        img = cv2.resize(img,(image_size,image_size))\n",
    "        X_train.append(img)\n",
    "        y_train.append(i)\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97bc889b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = shuffle(X_train,y_train,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89f9a85f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4764, 128, 128, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b57a8d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X_train,y_train,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f337fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_new=[]\n",
    "for i in y_train:\n",
    "    y_train_new.append(labels.index(i))\n",
    "y_train = y_train_new\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "\n",
    "y_test_new=[]\n",
    "for i in y_test:\n",
    "    y_test_new.append(labels.index(i))\n",
    "y_test = y_test_new\n",
    "y_test = tf.keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a736153a",
   "metadata": {},
   "source": [
    "## Defining the first model CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57fb57f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvBlock(model, layers, filters):\n",
    "    '''Create [layers] layers consisting of zero padding, a convolution with [filters] 3x3 filters and batch normalization. Perform max pooling after the last layer.'''\n",
    "    for i in range(layers):\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Conv2D(filters, (3, 3), activation='relu'))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "    model.add(MaxPooling2D((2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58a8f03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    '''Create the FCN and return a keras model.'''\n",
    "\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # Input image: 75x75x3\n",
    "    model.add(Lambda(lambda x: x, input_shape=(128, 128, 3)))\n",
    "    ConvBlock(model, 1, 32)\n",
    "    # 37x37x32\n",
    "    ConvBlock(model, 1, 64)\n",
    "    # 18x18x64\n",
    "    ConvBlock(model, 1, 128)\n",
    "    # 9x9x128\n",
    "    ConvBlock(model, 1, 256)\n",
    "    # 4x4x128\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(2, (1, 1), activation='relu'))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    # 4x4x2\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a20e80a",
   "metadata": {},
   "source": [
    "## Initialising the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28098d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 08:05:06.749133: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/dsam/anaconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2023-05-11 08:05:06.749603: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-05-11 08:05:06.749655: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (dsam-HP-ProBook-640-G1): /proc/driver/nvidia/version does not exist\n",
      "2023-05-11 08:05:06.750463: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8a2717",
   "metadata": {},
   "source": [
    "## Compiling te model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a06baf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=0.0001) , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c94162",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23329def",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69146b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, validation_split=0.4, batch_size=10, epochs=50, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc61288",
   "metadata": {},
   "source": [
    "## Model monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37dbd989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 8s 251ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "y_test_new = np.argmax(y_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f13b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a5a4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_new,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78a7b07",
   "metadata": {},
   "source": [
    "## Preparing dataset for the second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a1673d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels1=['pituitary_tumor','meningioma_tumor','glioma_tumor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9dc16b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 827/827 [00:02<00:00, 311.93it/s]\n",
      "100%|██████████| 822/822 [00:01<00:00, 425.40it/s]\n",
      "100%|██████████| 826/826 [00:01<00:00, 413.80it/s]\n",
      "100%|██████████| 74/74 [00:00<00:00, 193.25it/s]\n",
      "100%|██████████| 115/115 [00:00<00:00, 667.03it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 507.89it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train1 = []\n",
    "y_train1 = []\n",
    "image_size = 128\n",
    "for i in labels1:\n",
    "    folderPath = os.path.join('/home/dsam/AIMS_CMR/Essay_Alain/dataset/Get_to_work/Brain_to_work','Training',i)\n",
    "    for j in tqdm(os.listdir(folderPath)):\n",
    "        img = cv2.imread(os.path.join(folderPath,j))\n",
    "        img = cv2.resize(img,(image_size,image_size))\n",
    "        X_train1.append(img)\n",
    "        y_train1.append(i)\n",
    "for i in labels1:\n",
    "    folderPath = os.path.join('/home/dsam/AIMS_CMR/Essay_Alain/dataset/Get_to_work/Brain_to_work','Testing',i)\n",
    "    for j in tqdm(os.listdir(folderPath)):\n",
    "        img = cv2.imread(os.path.join(folderPath,j))\n",
    "        img = cv2.resize(img,(image_size,image_size))\n",
    "        X_train1.append(img)\n",
    "        y_train1.append(i)\n",
    "X_train1 = np.array(X_train1)\n",
    "y_train1 = np.array(y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6186ccb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, y_train1 = shuffle(X_train1,y_train1,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b7ae8e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2764, 128, 128, 3)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5824d46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1,X_test1,y_train1,y_test1=train_test_split(X_train1,y_train1,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "751ed7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_new1=[]\n",
    "for i in y_train1:\n",
    "    y_train_new1.append(labels1.index(i))\n",
    "y_train1 = y_train_new1\n",
    "y_train1 = tf.keras.utils.to_categorical(y_train1)\n",
    "\n",
    "y_test_new1=[]\n",
    "for i in y_test1:\n",
    "    y_test_new1.append(labels1.index(i))\n",
    "y_test1 = y_test_new1\n",
    "y_test1 = tf.keras.utils.to_categorical(y_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c88aa7",
   "metadata": {},
   "source": [
    "## Building the CNN for the second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6593920",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_rate=0.1\n",
    "    \n",
    "ini_input=keras.Input(shape=(128,128,3),name=\"image\")\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu',  padding='same')(ini_input)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Dropout(dropout_rate)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Conv2D(64, (3, 3), activation='relu',  padding='same')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Dropout(dropout_rate)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Dropout(dropout_rate)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Dropout(dropout_rate)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Conv2D(3, (1, 1))(x)\n",
    "x = Dropout(dropout_rate)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = GlobalMaxPooling2D()(x)\n",
    "predictions = Activation('softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6105e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=keras.Model(inputs=ini_input,outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "bf20e265",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr=0.00010,momentum=1, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ed81c5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(learning_rate=0.0001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7dfb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f9df1a",
   "metadata": {},
   "source": [
    "## Running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01faae25",
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = model2.fit(X_train1, y_train1, validation_split=0.4, batch_size=10, epochs=50, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc1088f",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "97c39c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 4s 195ms/step\n"
     ]
    }
   ],
   "source": [
    "pred2 = model2.predict(X_test1)\n",
    "pred2 = np.argmax(pred2,axis=1)\n",
    "y_test_new1 = np.argmax(y_test1,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e793c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_new1,pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c382524c",
   "metadata": {},
   "source": [
    "## Building dataset for the third model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b1cc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels2=['no_tumor','pituitary_tumor','meningioma_tumor','glioma_tumor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6e0f983e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 520.35it/s]\n",
      "100%|██████████| 150/150 [00:00<00:00, 333.36it/s]\n",
      "100%|██████████| 150/150 [00:00<00:00, 291.29it/s]\n",
      "100%|██████████| 150/150 [00:00<00:00, 433.93it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train2 = []\n",
    "y_train2 = []\n",
    "image_size = 128\n",
    "for i in labels2:\n",
    "    folderPath = os.path.join('/home/dsam/AIMS_CMR/Essay_Alain/dataset/Get_to_work/Brain_t2_work',i)\n",
    "    for j in tqdm(os.listdir(folderPath)):\n",
    "        img = cv2.imread(os.path.join(folderPath,j))\n",
    "        img = cv2.resize(img,(image_size,image_size))\n",
    "        X_train2.append(img)\n",
    "        y_train2.append(i)\n",
    "X_train2 = np.array(X_train2)\n",
    "y_train2 = np.array(y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "c813684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, y_train2 = shuffle(X_train2,y_train2,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "da21ca7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_new2=[]\n",
    "for i in y_train2:\n",
    "    y_train_new2.append(labels2.index(i))\n",
    "y_train2 = y_train_new2\n",
    "y_train2 = tf.keras.utils.to_categorical(y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83ff661",
   "metadata": {},
   "source": [
    "## Defining the third model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "1a82c13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Final_model3(Im_set):\n",
    "    y_pred = np.argmax(model.predict(Im_set.reshape(1,128,128,-1)))\n",
    "    if y_pred != 0:\n",
    "        y_pred = np.argmax(model2.predict(Im_set.reshape(1,128,128,-1)))+1\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b1f1f38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 5s 227ms/step\n",
      "15/15 [==============================] - 3s 188ms/step\n"
     ]
    }
   ],
   "source": [
    "y_predict =Final_model(X_train2)\n",
    "y_train_new2 = np.argmax(y_train2,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d069efa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.where(np.argmax(y_train2,axis=1)==0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "97d780d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(X_train2[x1[1]].reshape(1,128,128,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "db96ac9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = x[0][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "74a21b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = x[0]\n",
    "x2 = np.where(np.argmax(y_train2,axis=1)==1)[0]\n",
    "x3 = np.where(np.argmax(y_train2,axis=1)==2)[0]\n",
    "x4 = np.where(np.argmax(y_train2,axis=1)==3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dbdf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict2 = []\n",
    "for i in x1:\n",
    "    y_predict2.append(Final_model3(X_train2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6eea38",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict3 = []\n",
    "for i in x2:\n",
    "    y_predict3.append(Final_model3(X_train2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906d76d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict4 = []\n",
    "for i in x3:\n",
    "    y_predict4.append(Final_model3(X_train2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792ba032",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict5 = []\n",
    "for i in x4:\n",
    "    y_predict5.append(Final_model3(X_train2[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e9ab87",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "a3db40b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_predict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "3a707732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict2.count(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
